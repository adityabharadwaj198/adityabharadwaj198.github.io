<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-07-25T20:09:03+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Aditya Bharadwaj</title><subtitle>Technology Brother</subtitle><entry><title type="html">What the heck is the METEOR Score (and why I added it to Promptfoo)</title><link href="http://localhost:4000/blog/2025/07/25/meteor-score.html" rel="alternate" type="text/html" title="What the heck is the METEOR Score (and why I added it to Promptfoo)" /><published>2025-07-25T00:00:00+05:30</published><updated>2025-07-25T00:00:00+05:30</updated><id>http://localhost:4000/blog/2025/07/25/meteor-score</id><content type="html" xml:base="http://localhost:4000/blog/2025/07/25/meteor-score.html"><![CDATA[<p>I was recently going over Chip Huyen’s AI engineering book (if you want a quick beginner friendly compilation you should check out the book). In Chapter 3 of the book titled Evaluation Methodology, she mentions different kinds of Lexical similarity metrics - which include BLEU, METEOR &amp; ROUGE. It reminded me of the time when I implemented the METEOR metric for a eval + ai red teaming tool called Promptfoo. Let’s dive into it.</p>

<h2 id="first-off--what-is-meteor">First off — what is METEOR?</h2>

<p>METEOR stands for Metric for Evaluation of Translation with Explicit ORdering. Cool acronym, what does it do? idea behind it is:</p>

<p>“How similar is the model’s output to what I wanted it to say?”</p>

<p>It’s not just a simple string match. METEOR goes beyond that, it checks if the words match, whether they have the same root (stems), and even whether they’re synonyms. Oh, and it also factors in the word order.</p>

<h2 id="so-why-did-i-build-this-for-promptfoo">So why did I build this for Promptfoo?</h2>
<p>Promptfoo is a powerful open-source framework to test and benchmark LLM outputs. It supports all kinds of evaluation methods — from latency to cost to BLEU (I implemented this too!), GLEU, ROUGE and even model-graded evaluations.</p>

<p>But there was a missing piece in the lexical similarity toolkit. What we needed was a metric that:</p>

<p>Works well for short, structured outputs (like translations or summaries)
Can account for minor word reordering
Supports multiple valid reference outputs
Understands synonyms and stems</p>

<p><em>Oh, and they had an open issue where a Promptfoo user asked for being able to use the METEOR metric lol.</em></p>

<p>So I dived right into it and added METEOR support to Promptfoo.</p>

<h2 id="how-meteor-works-with-examples">How METEOR works (with examples)</h2>

<p>At a high level, METEOR compares a model-generated sentence with a reference by matching words in three stages:</p>

<ol>
  <li>
    <p>Exact word match</p>
  </li>
  <li>
    <p>Stemming match (e.g., “running” vs. “run”)</p>
  </li>
  <li>
    <p>Synonym match (e.g., “nice” vs. “beautiful”, using WordNet)</p>
  </li>
</ol>

<p>Once matches are found, it calculates precision and recall, applies a penalty for how fragmented the matches are (i.e. word order differences), and outputs a final score between 0 and 1.</p>

<p>Here’s a quick example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Reference:
The weather is beautiful today

Candidate outputs and expected scores (approximate):

The weather is beautiful today → 1.0 (exact match)

Today's weather is beautiful → ~0.85 (same words, reordered)

The weather is nice today → ~0.7 (synonym match on "nice")

It is sunny outside → ~0.3 (semantic drift, different words)
</code></pre></div></div>
<p>This kind of scoring is especially useful when there’s more than one “acceptable” phrasing — something that comes up constantly in LLM outputs.</p>

<p>Unlike BLEU or Levenshtein, METEOR gives partial credit for “close enough” matches while still penalizing structural changes when they matter.</p>

<h2 id="how-to-use-meteor-in-promptfoo">How to use METEOR in Promptfoo</h2>

<p>I wrote some documentation as part of my PR as well so I may as well point you directly to the documentation: https://www.promptfoo.dev/docs/configuration/expected-outputs/deterministic/#meteor</p>

<h2 id="when-should-you-use-meteor">When should you use METEOR?</h2>
<p>If your tests are judging:</p>

<ul>
  <li>Summaries</li>
  <li>Translations</li>
  <li>Short natural language answers</li>
</ul>

<p>Anywhere there’s more than one “valid” way to say something
…it’s a great tool.</p>

<h2 id="final-thoughts">Final Thoughts</h2>
<p>Adding METEOR to Promptfoo was fun, both as a coding problem (chunking, synonyms, scoring!) and as a UX enhancement for LLM evaluators. I usually don’t code in Typescript so it was a great exercise in that sense! Here’s my PR if interested to check it out: https://github.com/promptfoo/promptfoo/pull/3776/files</p>

<p>If you want to go beyond BLEU and get a more nuanced picture of output quality, give it a spin. Your tests will thank you. And your models might pass more often.</p>]]></content><author><name></name></author><category term="blog" /><category term="ai" /><category term="evals" /><category term="promptfoo" /><category term="lexical-similarity" /><summary type="html"><![CDATA[A quick dive into METEOR, a smarter evaluation metric for LLM outputs, and a behind-the-scenes look at how I implemented it for Promptfoo.]]></summary></entry><entry><title type="html">Get your head in the game</title><link href="http://localhost:4000/blog/2025/07/22/Get-your-head-in-the-game.html" rel="alternate" type="text/html" title="Get your head in the game" /><published>2025-07-22T00:00:00+05:30</published><updated>2025-07-22T00:00:00+05:30</updated><id>http://localhost:4000/blog/2025/07/22/Get%20your%20head%20in%20the%20game</id><content type="html" xml:base="http://localhost:4000/blog/2025/07/22/Get-your-head-in-the-game.html"><![CDATA[<p>Things I need to do to stay maximally productive (I forget these frequently)</p>

<p>I like being productive, it makes me not hate myself. dw I like having fun too, but I wanna feel like I’ve really exhausted myself being productive so that having fun really pays off. I don’t like having fun if I’ve not worked enough.</p>

<p>Things I need to do to stay maximally productive (I forget these frequently)</p>

<h2 id="go-to-the-gym">Go to the gym</h2>
<p>Reasons to consider:</p>
<ol>
  <li>The endorphin rush is real, mood is elevated, you start feeling good. This was so vague to me when I used to hear it from other people. During COVID WFH I worked out a lot and I’d always find myself being chirpier, singing songs, having fun &amp; being talkative with friends &amp; family if I met them right after the gym and that for me signals elevation of mood</li>
  <li>Energy levels post workout are higher. Again goes back to being chirpier, being talkative &amp; generally just thinking let’s get this shit done</li>
  <li>I feel productive by doing it. Let’s face it going to the gym is like any other task and if you do it you get to cut off a task from your todo list.</li>
  <li>It is absolutely the 1 thing in my life that I love
If not feeling like it, watch a workout video on the youtube: Omar Isuf / Jeff Nippard / Arnold / Saket Gokhale. These are some youtubers I like to watch.</li>
</ol>

<h2 id="drink-some-coffee-in-the-morning-with--without-protein">Drink some coffee in the morning with / without protein</h2>
<p>Helps me stay awake in the afternoon. Huberman’s golden rule is to drink after 90 minutes of waking up so try to stick to that</p>

<h2 id="keep-phone-away-in-another-room">Keep phone away in another room.</h2>
<p>Another thing to add here is to turn on self control for ~12 hours. I think we all struggle with scrolling X, this is one way to avoid it.</p>

<h2 id="if-not-getting-motivation">If not getting motivation</h2>
<h3 id="1-watching-naval--anyone-else-you-respect">1. Watching Naval / anyone else you respect</h3>

<h3 id="2-watch-striver-for-leetcode-motivation">2. Watch Striver for leetcode motivation.</h3>

<h2 id="always-make-a-to-do-list-for-the-day">Always make a to-do list for the day</h2>
<p>Even if you miss tasks, considering you complete &gt; 60% tasks, treat the day as a win. 
Another thing that I’ve found helpful is, to estimate the time required for a task &amp; write it down on your todo list. If a task takes ~5 minutes, do it right away. Then do other tasks in ascending order of time required.</p>

<h2 id="set-a-pomodoro-timer">Set a pomodoro timer</h2>
<p>I usually set one for 30 minutes + 5 minutes break, and if I’m flowing, then I hit multiple sessions back to back. Always respect the timer and don’t do anything else apart from productive work during this time.</p>

<h2 id="put-on-binaural-60-hz-augmented-gamma-beats">Put on binaural 60 hz augmented gamma beats</h2>
<p>or whatever the hell it’s called. I’ve heard it helps with focus. I usually put it on, maybe placebo but helps.</p>]]></content><author><name></name></author><category term="blog" /><category term="productivity" /><category term="reminders" /><category term="self" /><summary type="html"><![CDATA[Things I need to do to stay maximally productive (I forget these frequently)]]></summary></entry><entry><title type="html">What the heck is a vector embedding?</title><link href="http://localhost:4000/blog/2025/06/16/vectors.html" rel="alternate" type="text/html" title="What the heck is a vector embedding?" /><published>2025-06-16T00:00:00+05:30</published><updated>2025-06-16T00:00:00+05:30</updated><id>http://localhost:4000/blog/2025/06/16/vectors</id><content type="html" xml:base="http://localhost:4000/blog/2025/06/16/vectors.html"><![CDATA[<p>Vectors, Vector Embeddings, Vector Databases, and HNSW</p>

<h2 id="vectors">Vectors</h2>

<p>Vectors are interesting, they can pretty mean a lot of things in different contexts. In the context of the famed first programming language of every computer science student (C++), they may mean an array of N numbers (where N = 1 to X). In the context of physics they may mean something that has a certain direction. î (magnitude along x axis), ĵ (magnitude along y axis), k̂ (magnitude along z axis). Any point in 3D space can be represented by [x, y, z] coordinates which can be called a vector. We represent a location on the map with a vector of 2 dimensions (latitude and longitude).</p>

<p>To put it in context of the topic that we’re discussing, we can call vectors as arrays of length N, where N might be 3 (for a point in 3D space), 2 (for a point on a map), or even 768, 1024, 1536 etc. We just say N dimensions.</p>

<h2 id="vector-embeddings">Vector embeddings</h2>

<p>Models today are very powerful at one thing, they’re powerful at taking in a arbitrary piece of data (a word, a text, an image, an audio or even a video), and converting them to vector embeddings. These embeddings are just numerical representations of the input (in our case a word, a text, an image, an audio or even a video) that aim to capture meaning of the input, in N dimensions. The value of N depends on the Embedding Model that we’re using, but to generalize we could say that an Embedding Model is good at taking in an input, and spitting out a vector embedding.</p>

<p>Let’s say for an example, that a piece of text “A red dress”, has a vector embedding as: [1, 2, 3], let’s say (again for example) that this was generated by an Embedding  that spits out 3 dimensional embeddings. Models today are so good, that if you actually input an image of a red dress &amp; the Embedding  had to spit out a 3 dimensional embedding, it would give out something like a [1.1, 2.1, 2.9] as an ouput. Do you see how close it is to the original vector of the query? Our model inherently knows that the query “A red dress” and an actual image of the red dress are similar things, and so it outputs similar embeddings for both.</p>

<p>On a side note, a helpful tool to visualise vector embeddings for words in a 3D space is this embedding projector: https://projector.tensorflow.org/</p>

<h3 id="whats-a-embedding-model">What’s a Embedding model?</h3>

<ul>
  <li>I mentioned an Embedding model in a couple of places above, so I thought I should clarify: Embedding Models are Models trained especially to produce embeddings. They include open source models like BERT, CLIP (Constrastive Language-Image Pre-training) and Sentence Transformers.</li>
</ul>

<h2 id="vector-databases">Vector databases</h2>

<p>The bread and butter of vector databases is that a user should be able to put in a query (“A red dress”), and the Vector DB should be able to pull back the proper set of result (The image of the red dress, along with any other things that are similar to “A red dress”) as a response. BTW, a vector database doesn’t need you to tag that image of the red dress with something “red dress” or even “red” or even “dress”.
It has to do this at scale, out of billions of vectors (or how many ever vectors we’re storing).</p>

<p>One of the most popular vector search data structure / algorithm that Vector DBs use is HNSW (Heirarchical Navigable Small Worlds). HNSW sits at the core of systems like Weaviate, Elasticsearch, Vespa, OpenSearch, PGVector, and many others.</p>

<h2 id="hnsw">HNSW</h2>

<p>HNSW is a graph based algorithm used for approximate nearest neighbor (ANN) search in high-dimensional spaces, particularly in vector databases.</p>

<p>It works by starting at an arbitrary node in the graph, and then walking the graph to get closer to the vector embeddings of your input query.</p>

<p>Stay tuned for another article where I go over HNSW in depth!</p>]]></content><author><name></name></author><category term="blog" /><category term="vectors" /><category term="vector-search" /><category term="vector-db" /><category term="hnsw" /><summary type="html"><![CDATA[An introduction to vectors, vector embeddings, and vector databases.]]></summary></entry><entry><title type="html">Welcome to My Blog</title><link href="http://localhost:4000/blog/2024/03/20/welcome-to-my-blog.html" rel="alternate" type="text/html" title="Welcome to My Blog" /><published>2024-03-20T00:00:00+05:30</published><updated>2024-03-20T00:00:00+05:30</updated><id>http://localhost:4000/blog/2024/03/20/welcome-to-my-blog</id><content type="html" xml:base="http://localhost:4000/blog/2024/03/20/welcome-to-my-blog.html"><![CDATA[<p>Get a peek into my mind.</p>

<h2 id="what-to-expect">What to Expect</h2>

<p>In this blog, I’ll be writing about:</p>

<ul>
  <li>Personal projects and experiences</li>
  <li>My experiences with building my own X</li>
  <li>My experiences navigating the software engineering world</li>
  <li>Book / Album reviews and Songs / Artist recommendations</li>
  <li>History? Prehistoric India, IVC, Proto-Indo-Europeans [controversial stuff lol], Vedic age etc.</li>
</ul>

<h2 id="why-i-started-this-blog">Why I Started This Blog</h2>

<p>I am lazy and I never thought of writing anything more than what the educational curriculum 
demanded from me, but I have recently started to journal sometimes just to feel saner. 
I can’t pin-point what it does for me, other than make me feel good in some way.
For all I know it could be placebo. Anywhoo, I keep reading &amp; learning a 
lot of interesting things, that might be of interest in general to the
rest of the world (trust me), and what better way to explain something 
than to write it down in your own words. So this is my attempt at writing.</p>

<p>Through the blog I want to:</p>

<ol>
  <li>Document my learning journey</li>
  <li>Share insights that might help others</li>
  <li>Connect with like-minded individuals</li>
  <li>Build a portfolio of my thoughts and expertise</li>
  <li>Build my own corner of the internet :)</li>
</ol>

<h2 id="stay-connected">Stay Connected</h2>

<p>Feel free to reach out to me through any of the social links in the footer. I’m always happy to connect with fellow developers and technology enthusiasts!</p>

<p><em>Stay tuned for more posts coming soon!</em></p>]]></content><author><name></name></author><category term="blog" /><category term="welcome" /><category term="introduction" /><summary type="html"><![CDATA[Get a peek into my mind. I'll be writing about personal projects, software engineering experiences, book reviews, and even some controversial history topics like prehistoric India and the Vedic age.]]></summary></entry></feed>